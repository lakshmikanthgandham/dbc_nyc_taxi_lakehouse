{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7712e4ab-2635-4db2-9c1c-f3686caf98d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.sql.types import DoubleType, TimestampType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7f29aa1-1090-4220-b51c-d25fa35f765b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bronze_table_path = \"gs://databricks-glk-dbx-ext-storage/nyc_taxi_lakehouse/bronze/bronze_fhv_tripdata\"\n",
    "silver_table_path = \"gs://databricks-glk-dbx-ext-storage/nyc_taxi_lakehouse/silver/silver_fhv_tripdata\"\n",
    "\n",
    "catalog_name = \"nyc_taxi_catalog\"\n",
    "schema = \"nyc_taxi_lakehouse\"\n",
    "silver_table_name = \"silver_fhv_tripdata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d1b40de-63c3-4a32-a348-9e1dd8d01794",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"USE CATALOG {catalog_name}\")\n",
    "spark.sql(f\"USE SCHEMA {schema}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e35d708-d64c-4297-b823-97c679bc4091",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read bronze table\n",
    "df_bronze = spark.read.format(\"delta\").load(bronze_table_path)\n",
    "print(\"Bronze table read successfully\")\n",
    "df_bronze.printSchema()\n",
    "print(f\"Total number of bronze table : {df_bronze.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d4c377c-b913-4320-b49a-0eb7813d1b29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Deduplicate rows\n",
    "dedup_cols = [\"trip_id\"] if \"trip_id\" in df_bronze.columns else df_bronze.columns\n",
    "df_clean = df_bronze.dropDuplicates(dedup_cols)\n",
    "print(f\"Total rows after deduplication: {df_clean.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20fb2ccf-fe25-4898-8400-3d8f32b1179f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Typecasting columns\n",
    "\n",
    "typecast_mapping = {\n",
    "    \"pickup_datetime\": TimestampType(),\n",
    "    \"dropoff_datetime\": TimestampType(),\n",
    "    \"request_datetime\": TimestampType(),\n",
    "    \"on_scene_datetime\": TimestampType(),\n",
    "    \"base_passenger_fare\": DoubleType(),\n",
    "    \"tolls\": DoubleType(),\n",
    "    \"sales_tax\": DoubleType(),\n",
    "    \"congestion_surcharge\": DoubleType(),\n",
    "    \"tips\": DoubleType(),\n",
    "    \"driver_pay\": DoubleType(),\n",
    "    \"trip_miles\": DoubleType(),\n",
    "    \"trip_time\": DoubleType(),\n",
    "}\n",
    "\n",
    "for col_name,dtype in typecast_mapping.items():\n",
    "    if col_name in df_clean.columns:\n",
    "        df_clean = df_clean.withColumn(col_name, col(col_name).cast(dtype))\n",
    "\n",
    "# Null & invalid handling\n",
    "# Drop rows with critical nulls\n",
    "critical_cols = [c for c in [\"pickup_datetime\", \"dropoff_datetime\"] if c in df_clean.columns]\n",
    "if critical_cols:\n",
    "    df_clean = df_clean.dropna(subset=critical_cols)\n",
    "\n",
    "print(f\"Total rows after null handling: {df_clean.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "366c4f9b-12d6-4924-b540-725ce11bfc6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write to Silver Delta Table\n",
    "df_clean.write.mode(\"overwrite\").format(\"delta\").option(\"mergeSchema\",\"true\").save(silver_table_path)\n",
    "\n",
    "# Register table in catalog\n",
    "spark.sql(f\"drop table if exists {catalog_name}.{schema}.{silver_table_name}\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "          CREATE TABLE {catalog_name}.{schema}.{silver_table_name}\n",
    "          USING DELTA\n",
    "          LOCATION '{silver_table_path}'\n",
    "          \"\"\")\n",
    "print(\"Silver table created successfully and registered in catalog.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df9ee38a-ff19-4473-b20c-a5c379eb0a56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"select * from {catalog_name}.{schema}.{silver_table_name}\").limit(5).display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_cleaning_nyc_taxi",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
