{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eee7b390-2a90-4ae7-ba7a-d812075ed02d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_timestamp, col, lit\n",
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df90a14a-edfc-4be9-a0f4-388fe11c1fae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# GCS Paths\n",
    "raw_path = \"gs://databricks-glk-dbx-ext-storage/nyc_taxi_lakehouse/raw/\"\n",
    "bronze_table_path = \"gs://databricks-glk-dbx-ext-storage/nyc_taxi_lakehouse/bronze/bronze_fhv_tripdata\"\n",
    "tracking_table_path = \"gs://databricks-glk-dbx-ext-storage/nyc_taxi_lakehouse/bronze/ingested_files\"\n",
    "\n",
    "# Unity Catalog References\n",
    "catalog_name = \"nyc_taxi_catalog\"\n",
    "schema_name = \"bronze\"\n",
    "tracking_table_name = \"ingested_files\"\n",
    "tracking_table_fq = f\"{catalog_name}.{schema_name}.{tracking_table_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82d2fc79-8724-4bad-95d0-54ae15bf36ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE CATALOG IF NOT EXISTS {catalog_name}\n",
    "MANAGED LOCATION 'gs://databricks-glk-dbx-ext-storage/nyc_taxi_lakehouse/'\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(f\"USE CATALOG {catalog_name}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {schema_name}\")\n",
    "spark.sql(f\"USE SCHEMA {schema_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4146b7e-2ef0-42e2-abc1-d03d553027cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3Ô∏è‚É£ Identify already-ingested files\n",
    "# ------------------------------------------------------------\n",
    "try:\n",
    "    tracked_files_df = spark.read.format(\"delta\").load(tracking_table_path)\n",
    "    tracked_files = [row.file_name for row in tracked_files_df.collect()]\n",
    "except Exception:\n",
    "    tracked_files = []\n",
    "\n",
    "print(f\"Already tracked files: {tracked_files}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfc5f357-d368-4226-9ee4-dd0f8aa9538d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 4Ô∏è‚É£ List available raw files & pick next to ingest\n",
    "# ------------------------------------------------------------\n",
    "all_files = [f.path for f in dbutils.fs.ls(raw_path) if f.path.endswith(\".parquet\")]\n",
    "all_files = sorted(all_files)  # chronological order\n",
    "\n",
    "# Filter unprocessed files\n",
    "new_files = [f for f in all_files if f.split(\"/\")[-1] not in tracked_files]\n",
    "\n",
    "# Pick one file per run\n",
    "file_to_process = [new_files[0]] if new_files else []\n",
    "\n",
    "if not file_to_process:\n",
    "    print(\"‚úÖ No new files to process. All up to date.\")\n",
    "else:\n",
    "    print(f\"File to process in this run: {file_to_process}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71641d46-6ce7-4644-9c83-3a6e264fa53c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.parquet.outputTimestampType\", \"TIMESTAMP_MILLIS\")\n",
    "\n",
    "for file in file_to_process:\n",
    "    # Read raw parquet\n",
    "    df = spark.read.parquet(file)\n",
    "\n",
    "    # Normalize timestamp columns (avoid timestampNtz issue)\n",
    "    for cname, dtype in df.dtypes:\n",
    "        if dtype.startswith(\"timestamp\"):\n",
    "            df = df.withColumn(cname, col(cname).cast(\"string\"))\n",
    "\n",
    "    # Write to Bronze Delta table (create or append)\n",
    "    df.write.format(\"delta\") \\\n",
    "        .option(\"mergeSchema\", \"true\") \\\n",
    "        .mode(\"append\") \\\n",
    "        .save(bronze_table_path)\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 6Ô∏è‚É£ Update tracking Delta table\n",
    "    # ------------------------------------------------------------\n",
    "    filename = file.split(\"/\")[-1]\n",
    "\n",
    "    # Create DataFrame with file_name only\n",
    "    tracking_df = spark.createDataFrame([(filename,)], [\"file_name\"])\n",
    "\n",
    "    # Add ingestion timestamp\n",
    "    tracking_df = tracking_df.withColumn(\"ingestion_date\", current_timestamp())\n",
    "\n",
    "    # Append or overwrite tracking table\n",
    "    if tracked_files:\n",
    "        tracking_df.write.format(\"delta\").mode(\"append\").save(tracking_table_path)\n",
    "    else:\n",
    "        tracking_df.write.format(\"delta\").mode(\"overwrite\").save(tracking_table_path)\n",
    "\n",
    "    print(f\"‚úÖ File {filename} ingested successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eed40a6b-beba-49ad-bca3-f4e6d8344ccc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 7Ô∏è‚É£ Validate tracking entries\n",
    "# ------------------------------------------------------------\n",
    "print(\"üìã Tracking Table Contents:\")\n",
    "try:\n",
    "    spark.read.format(\"delta\").load(tracking_table_path).show()\n",
    "except Exception:\n",
    "    print(\"‚ö†Ô∏è Tracking table not found yet.\")\n",
    "\n",
    "print(\"üìã Bronze Table Contents:\")\n",
    "try:\n",
    "    display(spark.read.format(\"delta\").load(bronze_table_path).count())\n",
    "except Exception:\n",
    "    print(\"‚ö†Ô∏è Bronze table not found yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2156e728-7169-4bab-be24-295377863f1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"delta\").load(bronze_table_path)\n",
    "\n",
    "# Show schema\n",
    "df.printSchema()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "bronze_ingestion_nyc_taxi",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
